rook-ceph:
  monitoring:
    enabled: true

rook-ceph-cluster:
  monitoring:
    enabled: true
    createPrometheusRules: true
  cephClusterSpec:
    mon:
      count: 3
    mgr:
      count: 2
    dashboard:
      ssl: false
    logCollector:
apiVersion: ceph.rook.io/v1
kind: CephCluster
metadata:
  name: rook-ceph
  namespace: rook-ceph
spec:
  cephVersion:
    image: quay.io/ceph/ceph:v19.2.2
    allowUnsupported: false
  dataDirHostPath: /var/lib/rook
  skipUpgradeChecks: false
  continueUpgradeAfterChecksEvenIfNotHealthy: false
  waitTimeoutForHealthyOSDInMinutes: 10
  upgradeOSDRequiresHealthyPGs: false
  mon:
    count: 3
    allowMultiplePerNode: false
  mgr:
    count: 2
    allowMultiplePerNode: false
    modules:
      - name: rook
        enabled: true
  dashboard:
    enabled: true
    ssl: true
  monitoring:
    enabled: true
    metricsDisabled: false
    exporter:
      perfCountersPrioLimit: 5
      statsPeriodSeconds: 5
  network:
    connections:
      encryption:
        enabled: false
      compression:
        enabled: false
      requireMsgr2: false
  crashCollector:
    disable: false
  logCollector:
    enabled: true
    periodicity: daily
    maxLogSize: 500M
  cleanupPolicy:
    confirmation: ""
    sanitizeDisks:
      method: quick
      dataSource: zero
      iteration: 1
    allowUninstallWithVolumes: false
  removeOSDsIfOutAndSafeToRemove: false
  priorityClassNames:
    mon: system-node-critical
    osd: system-node-critical
    mgr: system-cluster-critical
  storage:
    useAllNodes: true
    useAllDevices: false
    deviceFilter: '^sd'  # Exemplo: usa apenas discos como sda, sdb, sdc (t√≠pico de SSDs SATA)
    config:
      deviceClass: ssd
    allowDeviceClassUpdate: false
    allowOsdCrushWeightUpdate: false
    scheduleAlways: false
    onlyApplyOSDPlacement: false
  disruptionManagement:
    managePodBudgets: true
    osdMaintenanceTimeout: 30
  csi:
    readAffinity:
      enabled: false
    removeOSDsIfOutAndSafeToRemove: true
    resources:
    cephfs: {}
  healthCheck:
    daemonHealth:
      mon:
        disabled: false
        interval: 45s
      osd:
        disabled: false
        interval: 60s
      status:
        disabled: false
        interval: 60s
    livenessProbe:
      mon:
        disabled: false
      mgr:
        limits:
          memory: 2Gi
        requests:
          cpu: 200m
          memory: 1Gi
        disabled: false
      osd:
        disabled: false
    startupProbe:
      mon:
        limits:
          memory: 3Gi
        requests:
          cpu: 200m
          memory: 1Gi
        disabled: false
      mgr:
        disabled: false
      osd:
        limits:
          memory: 6Gi
        requests:
          cpu: 500m
          memory: 2Gi
    storage:
      useAllNodes: true
      useAllDevices: false
      devices:
        - name: sdb
      config:
        osdsPerDevice: "1"

  cephBlockPools:
    - name: standard-rwo
      spec:
        replicated:
          size: 2
      storageClass:
        enabled: true
        name: standard-rwo
        isDefault: true
        allowVolumeExpansion: true
        parameters:
          imageFeatures: layering,fast-diff,object-map,deep-flatten,exclusive-lock
          csi.storage.k8s.io/provisioner-secret-name: rook-csi-rbd-provisioner
          csi.storage.k8s.io/provisioner-secret-namespace: "{{ .Release.Namespace }}"
          csi.storage.k8s.io/controller-expand-secret-name: rook-csi-rbd-provisioner
          csi.storage.k8s.io/controller-expand-secret-namespace: "{{ .Release.Namespace }}"
          csi.storage.k8s.io/node-stage-secret-name: rook-csi-rbd-node
          csi.storage.k8s.io/node-stage-secret-namespace: "{{ .Release.Namespace }}"

  cephBlockPoolsVolumeSnapshotClass:
    enabled: true
    isDefault: true

  cephFileSystems:
    - name: standard-rwx
      spec:
        metadataPool:
          replicated:
            size: 2
        dataPools:
          - name: data0
            replicated:
              size: 2
        metadataServer:
          activeCount: 1
          activeStandby: true
          resources:
            limits:
              memory: 4Gi
            requests:
              cpu: 100m
              memory: 100Mi
          priorityClassName: system-cluster-critical
      storageClass:
        enabled: true
        name: standard-rwx
        isDefault: false
        allowVolumeExpansion: true
        pool: data0
        parameters:
          csi.storage.k8s.io/provisioner-secret-name: rook-csi-cephfs-provisioner
          csi.storage.k8s.io/provisioner-secret-namespace: "{{ .Release.Namespace }}"
          csi.storage.k8s.io/controller-expand-secret-name: rook-csi-cephfs-provisioner
          csi.storage.k8s.io/controller-expand-secret-namespace: "{{ .Release.Namespace }}"
          csi.storage.k8s.io/node-stage-secret-name: rook-csi-cephfs-node
          csi.storage.k8s.io/node-stage-secret-namespace: "{{ .Release.Namespace }}"

  cephFileSystemVolumeSnapshotClass:
    enabled: true
    isDefault: false

  cephObjectStores: []


